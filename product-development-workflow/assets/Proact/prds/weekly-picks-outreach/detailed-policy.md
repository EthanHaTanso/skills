# Weekly Picks Outreach 정책서 (상세)

**Last Updated**: 2026년 1월 22일
**Related Documents**:

- PRD 문서: [weekly-picks-outreach-prd.md](./weekly-picks-outreach-prd.md)
- Knowledge Base: [proact-knowledge-base.md](../proact-knowledge-base.md)

---

## 1. 기능 개요

### 배경

Weekly Picks Outreach는 Proact의 기존 자산(Weekly Picks 공고 + 60k 컨택리스트)을 활용하여 **외부 유저 유입을 자동화**하는 시스템이다.

**현재 상황:**

- Proact는 매주 ~2,000개의 새로운 정부 입찰 공고를 수집하고 키워드/설명을 추출
- 60k+ SAM.gov 등록 기업의 컨택 정보와 비즈니스 요약 보유
- 기존 콜드메일은 "적시성 부재" 문제 (수신자의 현재 B2G 관심도 알 수 없음)

**이 시스템이 하는 일:**

- 매주 각 기업에 맞는 Top 5 공고를 자동 매칭
- "왜 이 공고가 당신에게 맞는지" 개인화된 설명 생성
- Landing Page 유입을 통한 회원가입/전환 유도

### 핵심 가치

- **적시성 (Timeliness)**: 일반적인 B2G 권유가 아닌, 이번 주 실제 공고 기반 구체적 제안
- **개인화 (Personalization)**: 기업의 비즈니스 포트폴리오와 공고의 연관성을 명시적으로 설명
- **지속성 (Sustainability)**: 일회성 콜드메일이 아닌, 매주 새 콘텐츠로 반복 가능한 시스템
- **효율성 (Efficiency)**: 2-Stage 매칭으로 LLM 비용 최적화, 자동화된 파이프라인

---

## 2. 유저 상황과 기대

### 2.1. 운영자 (Proact 팀) 관점

**운영자가 이 시스템을 실행할 때의 심리:**

- "이번 주 Weekly Picks가 업데이트됐으니, Outreach 파이프라인을 돌려야지"
- "비용이 얼마나 들지? 지난주 대비 성과가 어땠지?"
- "매칭 품질이 괜찮은지 샘플로 확인해봐야겠다"

**운영자에게 제공해야 할 경험:**

1. **투명한 진행 상황** — 파이프라인 단계별 진행률과 예상 완료 시간
2. **비용 가시성** — LLM 호출 수, 예상 비용, 이메일 발송 수
3. **품질 검증 도구** — 샘플 매칭 결과 미리보기, 이메일 프리뷰
4. **성과 대시보드** — 발송 후 Open/Click/전환 추적

### 2.2. 이메일 수신자 (외부 기업) 관점

**수신자가 이메일을 열었을 때의 심리:**

- "또 스팸인가? 빨리 판단하고 넘어가야지"
- "음? 우리 회사 이름이 있네. 한 번 볼까?"
- "이 공고가 진짜 우리랑 맞나? 왜 맞다고 하는 거지?"

**수신자에게 제공해야 할 경험:**

1. **즉각적 관련성 인식** — 첫 눈에 "이건 나를 위한 거구나" 느낌
2. **구체적 연결고리** — "당신의 [X]가 이 공고의 [Y]와 연관됩니다" 명확한 설명
3. **낮은 인지 부하** — 5개 공고 중 1개만 관심 가도 성공, 빠른 스캔 가능
4. **명확한 다음 단계** — "더 알아보려면 여기 클릭" 단일 CTA

---

## 3. 주요 UX 원칙

### 3.1. 콘텐츠 우선 (Content-First)

- 개인화 느낌보다 **콘텐츠의 유효성**이 우선
- 5개 공고 중 1개만 관련 있어도 수신자에게 가치 전달
- **의도**: 매칭 정밀도가 완벽하지 않아도, 다수 제안으로 커버. 수신자가 직접 필터링하는 부담을 감수

### 3.2. 이유 제시 (Explain Why)

- 단순히 공고 나열이 아닌, **왜 이 공고가 당신에게 맞는지** 설명
- Company Portfolio의 키워드와 공고 Scope of Work의 연결점 명시
- **의도**: "이 회사가 내 비즈니스를 이해하고 있구나" 신뢰 구축

### 3.3. 점진적 참여 유도 (Progressive Engagement)

| 단계            | 목표        | 수신자 액션            |
| --------------- | ----------- | ---------------------- |
| **이메일 오픈** | 관심 유발   | 제목 + 첫 문장 읽기    |
| **스캔**        | 관련성 판단 | 5개 공고 제목 훑어보기 |
| **Why 확인**    | 신뢰 구축   | 관심 공고의 설명 읽기  |
| **CTA 클릭**    | 전환        | Landing Page 방문      |

- **의도**: 한 번에 모든 정보를 주지 않고, 단계별로 관심을 끌어올림

### 3.4. 비용 효율적 품질 (Cost-Efficient Quality)

- 2-Stage 매칭: Embedding으로 후보군 축소 → LLM으로 정밀 검증
- LLM 호출은 Top N 후보에 대해서만 (전체 60k × 2k = 120M 쌍 중 극히 일부)
- **의도**: 무한한 LLM 비용 없이 개인화된 품질 달성

---

## 4. 상세 유저 플로우

### 4.1. 파이프라인 실행 플로우 — 운영자

**상황**

- Weekly Picks가 업데이트된 직후 (보통 주 초)
- 운영자가 Outreach 파이프라인을 시작하려 함

**플로우**

1. **파이프라인 트리거**:
   - 운영자가 스크립트 실행 또는 자동 스케줄 트리거
   - 입력: OpenSearch에서 이번 주 Weekly Picks ID 목록 자동 조회, Google Spreadsheet에서 대상 컨택리스트 자동 불러오기
   - 출력: 파이프라인 실행 ID

2. **Stage 1 - Embedding 매칭**:
   - Company Summary/Portfolio → Embedding 생성 (최초 1회 또는 갱신 시)
   - 공고 Description → Embedding 생성
   - 각 기업당 Top N 공고 추출 (유사도 기준)
   - 진행률 표시: "Stage 1: 45,000 / 60,000 기업 처리 완료"

3. **Stage 2 - LLM 검증 및 Why Relevant 생성**:
   - 각 기업의 Top N 공고에 대해 LLM 호출
   - 관련성 판단 (Yes/No + Confidence) + Why Relevant 생성
   - 최종 Top 5 선정
   - 진행률 표시: "Stage 2: 30,000 / 60,000 기업 LLM 검증 완료"

4. **결과 저장**:
   - 기업별 최종 Top 5 공고 + Why Relevant 텍스트 저장
   - 발송 대기 큐에 추가

**디자인 의도**

- 운영자가 진행 상황을 실시간으로 파악할 수 있어야 함
- 중간에 문제 발생 시 어디서 멈췄는지 알 수 있어야 함

---

### 4.2. 품질 검증 플로우 — 운영자

**상황**

- 파이프라인 완료 후, 발송 전 품질 확인이 필요함

**플로우**

1. **샘플 추출**:
   - 랜덤 또는 NAICS 기반으로 50-100개 기업 샘플 추출
   - 각 기업의 매칭 결과 (Top 5 공고 + Why Relevant) 조회

2. **매칭 품질 평가**:
   - 운영자가 Company Summary/Business Portfolio와 매칭된 공고를 비교
   - "이 매칭이 말이 되는가?" 주관적 평가
   - 또는 LLM-as-judge로 자동 평가

3. **이메일 프리뷰**:
   - 실제 발송될 이메일 형태로 렌더링
   - 제목, 본문, CTA 확인
   - 문제 있으면 템플릿 수정 후 재생성

4. **발송 승인**:
   - 품질 OK → 발송 큐 활성화
   - 품질 문제 → 파이프라인 재실행 또는 파라미터 조정

**디자인 의도**

- 대량 발송 전 최소한의 품질 게이트
- 자동화와 수동 검증의 균형

---

### 4.3. 이메일 수신 플로우 — 외부 기업

**상황**

- SAM.gov에 등록했지만 Award 이력 없는 기업의 담당자
- Proact를 모르거나 들어본 적 있는 상태

**플로우**

1. **이메일 수신**:
   - 제목: "이번 주 [Company_Name]을 위한 Top 5 B2G 기회"
   - 발신자: Proact 또는 개인 이름 (A/B 테스트)

2. **첫 인상 판단** (2-3초):
   - 제목에서 회사 이름 인식 → "스팸은 아닌 것 같다"
   - 본문 첫 줄: "이번 주 새로 올라온 정부 입찰 공고 중..."
   - 관련성 판단: 계속 읽을지 / 삭제할지

3. **공고 스캔** (10-20초):
   - 5개 공고 제목을 빠르게 훑어봄
   - 1개라도 관심 가는 키워드 발견 → 해당 공고의 Why Relevant 읽기
   - 전부 무관해 보임 → 이메일 닫기

4. **Why Relevant 확인** (20-30초):
   - "당신의 [Cloud Migration 경험]이 이 공고의 [Data Center Modernization 요구사항]과 연관됩니다"
   - "오, 이 회사가 우리 비즈니스를 알고 있네"
   - 신뢰 형성 → CTA 고려

5. **CTA 클릭**:
   - "Proact에서 더 알아보기" 버튼 클릭
   - Landing Page로 이동
   - 회원가입 또는 이탈

**디자인 의도**

- 수신자의 시간은 소중함. 빠른 스캔으로 관련성 판단 가능해야 함
- Why Relevant가 신뢰의 핵심. "이 추천이 랜덤이 아니구나" 느낌 전달
- CTA는 단일하고 명확하게

---

### 4.4. 이메일 콘텐츠 구조 — 상세

**상황**

- 이메일 템플릿 설계 시 고려해야 할 구조

**플로우**

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[제목]
이번 주 {Company_Name}을 위한 Top 5 B2G 기회

[프리헤더]
{First_Name}님, 새로운 정부 입찰 공고가 도착했습니다

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Hi {First_Name},

이번 주 새로 올라온 정부 입찰 공고 중,
{Company_Name}의 비즈니스와 연관성이 높아 보이는 기회들입니다.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

🎯 #1. {Opportunity_Title_1}
   Agency: {Agency_Name} | Due: {Due_Date}

   왜 관련있나요?
   → {Why_Relevant_1}

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

🎯 #2. {Opportunity_Title_2}
   ...

(총 5개 반복)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

이 기회들로 첫 B2G Success Case를 만들어보고 싶으시다면?

        [ Proact에서 더 알아보기 ]

1,000+ B2G 전문 벤더들의 도움을 받을 수 있습니다.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[Footer]
더 이상 받고 싶지 않으시면 [구독 취소]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**디자인 의도**

- 제목에 회사 이름 포함 → 개인화 느낌 + 스팸 필터 우회
- 각 공고마다 Why Relevant 바로 아래 배치 → 스캔 용이
- CTA 버튼은 1개만 → 명확한 액션
- 구독 취소 제공 → CAN-SPAM 준수 + 리스트 품질 유지

---

### 4.5. 성과 추적 플로우 — 운영자

**상황**

- 이메일 발송 후, 성과를 추적하고 분석해야 함

**플로우**

1. **실시간 지표 확인**:
   - Open Rate: 몇 %가 이메일을 열었는가
   - Click Rate: 몇 %가 CTA를 클릭했는가
   - Bounce Rate: 몇 %가 반송되었는가

2. **전환 추적**:
   - Landing Page 방문 수
   - 회원가입 수
   - 유료 전환 수 (장기)

3. **세그먼트 분석**:
   - NAICS 코드별 성과 차이
   - Embedding 방식별 성과 (Keyword vs Description)
   - 시간대별 오픈율

4. **최적화 결정**:
   - 성과 좋은 세그먼트 → 확대
   - 성과 나쁜 세그먼트 → 원인 분석 또는 제외
   - 다음 주 파이프라인에 반영

**디자인 의도**

- 데이터 기반 의사결정 가능하게
- 점진적 최적화 사이클 구축

---

## 5. 엣지 케이스 및 예외 처리

### 5.1. 매칭 결과 없음

- **상황**: 특정 기업의 Company Summary가 너무 일반적이어서 관련 공고를 찾지 못함
- **처리**: 해당 기업은 이번 주 발송 대상에서 제외
- **로깅**: "매칭 실패 기업" 목록 별도 관리, 향후 데이터 보강 대상

### 5.2. Why Relevant 생성 실패

- **상황**: LLM 호출 실패 또는 생성된 설명이 부적절
- **처리**:
  - 재시도 (최대 3회)
  - 실패 시 해당 공고는 제외하고 차순위 공고로 대체
  - 전체 5개 미만이면 해당 기업 발송 제외
- **로깅**: 실패 케이스 기록, 패턴 분석

### 5.3. 이메일 반송 (Bounce)

- **상황**: 이메일 주소 무효 또는 수신 거부
- **처리**:
  - Hard Bounce: 컨택리스트에서 해당 이메일 비활성화
  - Soft Bounce: 3회 연속 실패 시 비활성화
- **목적**: 도메인 reputation 보호

### 5.4. 중복 공고 매칭

- **상황**: 같은 공고가 여러 기업의 Top 5에 반복 등장
- **처리**: 정상 케이스. 각 기업에 독립적으로 발송
- **참고**: Algorithm A에서는 Edge case 정책 적용 (상위 공고로 귀속)

### 5.5. 기업 정보 불완전

- **상황**: Company_Summary 또는 Business_Portfolio가 비어있거나 너무 짧음
- **처리**:
  - 최소 50자 이상 요구
  - 미달 시 발송 대상에서 제외
- **향후**: 해당 기업 데이터 보강 대상으로 플래그

---

## 6. 향후 고려사항

### 6.1. Algorithm A 도입

- **현재**: Algorithm B로 시작 (기업당 Top 5 공고)
- **향후**: 매칭 품질 검증 후 Algorithm A 시도 (공고당 Top 100 기업)
- **차이점**: 1:1 제안 + Teaming 파트너 연결

### 6.2. A/B 테스트 프레임워크

- **현재**: 수동으로 Keyword vs Description 비교
- **향후**:
  - 제목 변형 테스트
  - CTA 문구 테스트
  - 발송 시간대 테스트
  - 자동화된 A/B 분할 및 성과 비교

### 6.3. 뉴스레터 구독 모델

- **현재**: 단발성 Outreach
- **향후 옵션**:
  - "매주 B2G 공고 받아보기" 구독 동의 유도
  - 구독자 전환 시 더 높은 engagement 기대

### 6.4. Teaming 파트너 연결

- **현재**: CTA는 Landing Page 방문만
- **향후**:
  - 특정 공고에 경험 있는 Prime Contractor 소개
  - "이 Agency와 일해본 파트너가 있습니다" 가치 제안

---

## 7. 핵심 메트릭

| 메트릭                       | 설명                            | 목표                               |
| ---------------------------- | ------------------------------- | ---------------------------------- |
| **Open Rate**                | 이메일 오픈 비율                | 40%+ (현재 콜드메일 baseline 대비) |
| **CTR (Click-Through Rate)** | CTA 클릭 비율                   | 10%+                               |
| **Conversion Rate**          | 회원가입 / 클릭                 | 5%+                                |
| **CAC**                      | 신규 가입당 비용 (LLM + 이메일) | 측정 후 최적화                     |
| **Bounce Rate**              | 이메일 반송 비율                | 2% 이하                            |
| **Unsubscribe Rate**         | 구독 취소 비율                  | 1% 이하                            |

---

## 8. 정책 요약

1. **Algorithm B 우선**: MVP는 기업당 Top 5 공고 추천, 매칭 품질 검증 후 Algorithm A 시도
2. **2-Stage 매칭**: Embedding으로 후보 축소 → LLM으로 검증 및 Why Relevant 생성
3. **Why Relevant 필수**: 모든 추천 공고에 "왜 관련있는지" 설명 포함
4. **품질 게이트**: 발송 전 샘플 검증, 불완전 데이터 기업은 제외
5. **성과 추적**: Open/Click/전환 추적하여 점진적 최적화
6. **비용 투명성**: LLM 호출 수, 이메일 발송 수, 예상 비용 실시간 가시화
